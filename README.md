# Market Intelligence System

## Repo Overview
This repository contains foundational documents and prototype components for a machine learning-based optimization engine designed to dynamically balance pricing and fulfillment in a two-sided Facilities Maintenance marketplace. What I am referring to as the "engine" is really 4 components: an ML model that predicts elasticity of demand, an ML model that predicts elasticity of supply, a bridge layer that allows their outputs to be linked so that real seasonal outcomes can be simulated at the time of an RFP, and finally the optimization loop that links it all together to guide pricing toward the profit-maximizing outcome - both maximizing price on the customer side, prior to the season; and minimizing price on the provider side, during the season; effectively choosing the optimal mix of revenue, cost, and volume to maximize GP. The combination of these parts working together in unison forms a cohesive engine, which will be the heart of what I am calling the first true FM "Market Intelligence System".

**Please refer to the "Market Optimization Engine Blueprint" pdf in this repo for a comprehensive summary of the vision, which will also help to explain the structure of the repo.**

## Current Progress

The project is in its early stages - I currently have a beta customer price sensitivity model trained using logistic regression which predicts probability of winning a contract based on the hourly rate that is presented to the customer for the handyman trade (classification model). In the optimization loop, I call this model in conjunction with a static county-level provider rate sheet to determine profit maximizing customer bid rates for each county in the US. I  built a Streamlit app which is driven by that optimization script, which will return optimal rate for any address in the US that you enter, along with some other information like the anticipated win rate, the target margin, and the anticipated provider rate (in this case fixed, but not intended to be in future iterations once a provider price sensitivity model is trained).

## Roadmap

1. Today I am actively working to source the data I need to train a tree model (regression model) to predict revenue realization as a function of customer hourly rate presented on the bid, in conjunction with several other features. I chose to go this route because a simple yes/no on the bid does not correlate at all to actual customer spend. These are non routine contracts where the customer agrees to certain prices on a rate sheet, but has no obligation to actually call us for work. The better gauge of customer response to price (and other features) is actual conversion/spend. This has been somewhat challenging to link accurately but I now have the data I need from Snowflake to link revenue to a specific trade and bid (the approach was to track spend on a store level for that trade in the 12 months subsequent to the bid's award date).
2. Once I have a tree model trained and generalizing well using XGBoost I have a much more robust customer elasticity model, and can shift my attention to building a provider elasticity model. This model will be trained on the job level, rather than on the annualized spend per store level, because of the nature of the industry (customers make pricing decisions once per year at a regional or statewide level, providers make pricing decisions on every individual job). There are challenges to be faced here but the ultimate outcome will be a model that predicts the minimum viable rate to fill a job within acceptable timing and quality constraints, given several features like recent demand, location, customer size, job complexity, etc.
3. With the provider model trained, I will shift my attention to building a bridge layer, which will leverage historical seasonal job data to simulate a job mix over the course of an entire season for each store location, based on the revenue target that the customer model predicts. These jobs, with all of their individual characteristics and seasonal variations around proximate demand volume, will be individuall fed to the provider model to determine minimum viable rates to ensure job fulfillment, and then with that knowledge the bridge layer will predict the total cost of each job provider-side.
4. With total revenue and total cost now generated, the optimization loop simply repeats the process over an entire range of customer hourly rates and solves for the profit-maximizing mix. Ultimately it returns a suggested rate to present on the bid for each location, which can then be aggregated to whatever level of generality the RFP is requiring pricing to be presented at.

`THIS REPO IS SANITIZED OF ALL COMPANY SENSITIVE DATA AND INFORMATION - ANY DATA FOUND IN THE REPO HAS BEEN FABRICATED AS A STAND-IN AND IS NOT REPRESENTATIVE OF ACTUAL COMPANY DATA.`


